# ğŸ¯ Voice Deepfake Detection System

**Real-time AI-powered voice deepfake detection using AASIST neural architecture**

A production-ready web application that detects AI-generated voice deepfakes with high accuracy, supporting both professional studio recordings and consumer-grade microphones.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7+-red.svg)](https://pytorch.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‚ PROJECT STRUCTURE

```
Voice_Deepfake_Detection/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         â† Project documentation (this file)
â”œâ”€â”€ ğŸ”§ utils.py                          â† Dataset utilities & testing tools
â”œâ”€â”€ ğŸ“ train_comprehensive.py            â† Comprehensive training script
â”œâ”€â”€ ğŸŒ serve_https.py                    â† HTTPS frontend server (port 3000)
â”œâ”€â”€ ğŸ“„ comprehensive_push.py             â† Git automation script
â”‚
â”œâ”€â”€ ğŸ“ backend/                          â† Flask REST API + Deep Learning Model
â”‚   â”œâ”€â”€ requirements.txt                 â† Python dependencies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ aasist.py                    â† AASIST model architecture (5.4M params)
â”‚   â”‚   â”œâ”€â”€ app.py                       â† Flask API endpoints
â”‚   â”‚   â”œâ”€â”€ enhanced_detector.py         â† Enhanced TTS detection wrapper
â”‚   â”‚   â””â”€â”€ feature_extractor.py         â† Audio feature extraction
â”‚   â”œâ”€â”€ checkpoints/                     â† Trained model weights
â”‚   â”‚   â”œâ”€â”€ zero_download_model.pth      â† Production model (20.82 MB)
â”‚   â”‚   â””â”€â”€ best.pth                     â† Base model checkpoint (20.82 MB)
â”‚   â””â”€â”€ uploads/                         â† Temporary audio file storage
â”‚
â”œâ”€â”€ ğŸ“ frontend/                         â† React Web Interface
â”‚   â””â”€â”€ dist/                            â† Production build
â”‚       â”œâ”€â”€ index.html                   â† Main HTML file
â”‚       â””â”€â”€ assets/                      â† CSS/JS bundles
â”‚
â”œâ”€â”€ ğŸ“ certificates/                     â† SSL certificates for HTTPS
â”‚   â”œâ”€â”€ cert.pem                         â† SSL certificate
â”‚   â””â”€â”€ key.pem                          â† Private key
â”‚
â””â”€â”€ ğŸ“ data/                             â† Training datasets (not in repo)
    â”œâ”€â”€ ASVspoof2019/                    â† ASVspoof 2019 LA dataset
    â”œâ”€â”€ downloaded_dataset/              â† LibriSpeech test-clean
    â””â”€â”€ your_voice_samples/              â† Custom voice recordings
```

---

## ğŸš€ QUICK START

### Prerequisites

- Python 3.8 or higher
- NVIDIA GPU with CUDA support (recommended) or CPU
- Windows/Linux/macOS

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/anjo3902/Voice_Deepfake_Detection.git
cd Voice_Deepfake_Detection
```

2. **Create virtual environment**
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r backend/requirements.txt
```

### Running the Application

#### Option 1: Run Backend and Frontend Separately

**Terminal 1 - Backend API (Port 5000):**
```bash
cd backend/models
python app.py
```

**Terminal 2 - Frontend Server (Port 3000):**
```bash
python serve_https.py
```

Then open your browser:
- **Frontend**: https://localhost:3000
- **Backend API**: https://localhost:5000

> **Note**: You'll see a security warning about self-signed SSL certificates. Click "Advanced" â†’ "Proceed to localhost" to continue.

#### Option 2: Quick Test via API

```python
import requests

# Test the API
response = requests.post(
    'https://localhost:5000/predict',
    files={'file': open('test_audio.wav', 'rb')},
    verify=False  # Skip SSL verification for self-signed cert
)

print(response.json())
# Output: {"is_fake": false, "confidence": 0.9234, "prediction": "REAL"}
```

---

## ğŸ“Š KEY FEATURES

### âœ¨ Core Capabilities

- **ğŸ¯ High Accuracy**: 89.59% detection accuracy on diverse voice samples
- **âš¡ Real-Time Processing**: ~76.8ms inference time per 4-second audio clip
- **ğŸ¤ Consumer Microphone Support**: Works with laptops, USB mics, and phone recordings
- **ğŸŒ Web Interface**: User-friendly React-based frontend with drag-and-drop upload
- **ğŸ”’ Secure HTTPS**: SSL-enabled backend and frontend servers
- **ğŸ”„ RESTful API**: Easy integration with other applications
- **ğŸ“Š Confidence Scoring**: Detailed prediction confidence levels
- **ğŸµ Multiple Format Support**: WAV, FLAC, MP3, M4A, OGG

### ğŸ§  Technical Features

- **AASIST Architecture**: State-of-the-art neural network (5.4M parameters)
- **CUDA Acceleration**: GPU-accelerated inference on NVIDIA GPUs
- **Robust Feature Extraction**: LFCC, Spectral, and Sinc-based features
- **Batch Processing**: Efficient handling of multiple audio files
- **Comprehensive Training**: Trained on ASVspoof2019 + LibriSpeech + custom datasets

---

## ğŸ“ MODEL DETAILS

### Architecture: AASIST (Audio Anti-Spoofing using Integrated Spectro-Temporal graph attention)

| Parameter | Value |
|-----------|-------|
| **Model Type** | Graph Attention Network + ResNet |
| **Total Parameters** | 5.4 Million |
| **Input** | Raw audio waveform (16kHz, mono) |
| **Output** | Binary classification (Real/Fake) + Confidence |
| **Inference Time** | 14.8ms per 4-second clip (GPU) |
| **Model Size** | 20.82 MB |
| **Framework** | PyTorch 2.7+ |

### Training Details

- **Primary Dataset**: ASVspoof 2019 Logical Access (LA) subset
- **Supplementary Data**: LibriSpeech test-clean, custom recordings
- **Training Strategy**: Comprehensive training to prevent catastrophic forgetting
- **Optimizer**: Adam with learning rate 0.0001
- **Loss Function**: Cross-Entropy Loss
- **Batch Size**: 16
- **Hardware**: NVIDIA RTX 2050 4GB VRAM

### Performance Metrics

| Metric | Value |
|--------|-------|
| **Overall Accuracy** | 89.59% |
| **Validation Accuracy** | 92.3% |
| **False Positive Rate** | ~8.5% |
| **Inference Latency** | 76.8ms |

---

## ğŸ”§ TRAINING (OPTIONAL)

The repository includes pre-trained models, but you can retrain if needed:

### 1. Download Training Datasets

```bash
# Download LibriSpeech test-clean subset (~350MB)
python utils.py download
```

### 2. Prepare ASVspoof2019 Dataset

Download ASVspoof2019 LA dataset from [official source](https://datashare.ed.ac.uk/handle/10283/3336) and extract to:
```
data/ASVspoof2019/LA/
â”œâ”€â”€ ASVspoof2019_LA_train/flac/
â”œâ”€â”€ ASVspoof2019_LA_dev/flac/
â””â”€â”€ ASVspoof2019_LA_cm_protocols/
```

### 3. Train Comprehensive Model

```bash
python train_comprehensive.py
```

This trains a comprehensive model that includes:
- âœ… ASVspoof traditional TTS spoofs
- âœ… Modern neural TTS (ElevenLabs, modern systems)
- âœ… Real voices from LibriSpeech
- âœ… Custom voice recordings

**Training Output**: New checkpoint saved to `backend/checkpoints/`

---

## ğŸ§ª TESTING & UTILITIES

The `utils.py` script provides several helpful utilities:

```bash
# Download LibriSpeech test dataset
python utils.py download

# Test model on diverse speakers
python utils.py test

# Generate performance graphs
python utils.py graphs

# Run all utilities
python utils.py all

# Show help
python utils.py help
```

---

## ğŸ“ QUICK REFERENCE

| Task | Command |
|------|---------|
| **Install dependencies** | `pip install -r backend/requirements.txt` |
| **Run backend API** | `cd backend/models && python app.py` |
| **Run frontend server** | `python serve_https.py` |
| **Download datasets** | `python utils.py download` |
| **Train model** | `python train_comprehensive.py` |
| **Test model** | `python utils.py test` |
| **Generate graphs** | `python utils.py graphs` |

---

## ğŸ“¡ API REFERENCE

### Base URL
```
https://localhost:5000
```

### Endpoints

#### 1. Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "device": "cuda"
}
```

#### 2. Predict Audio Authenticity
```http
POST /predict
Content-Type: multipart/form-data
```

**Parameters:**
- `file`: Audio file (WAV, FLAC, MP3, M4A, OGG)
- Max size: 100MB
- Recommended: 4-second clips at 16kHz

**Response (Real Audio):**
```json
{
  "is_fake": false,
  "confidence": 0.9234,
  "prediction": "REAL"
}
```

**Response (Fake Audio):**
```json
{
  "is_fake": true,
  "confidence": 0.8712,
  "prediction": "FAKE"
}
```

---

## ğŸ—ï¸ SYSTEM ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USER INTERFACE (React)                    â”‚
â”‚            https://localhost:3000                           â”‚
â”‚         [Drag & Drop] [Upload] [Results Display]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTPS Request
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FLASK REST API                            â”‚
â”‚              https://localhost:5000                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Receive & Validate Audio                        â”‚   â”‚
â”‚  â”‚  2. Feature Extraction (LFCC, Spectral)             â”‚   â”‚
â”‚  â”‚  3. AASIST Model Inference                          â”‚   â”‚
â”‚  â”‚  4. Return Prediction + Confidence                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AASIST MODEL (GPU)    â”‚
â”‚   5.4M Parameters       â”‚
â”‚   CUDA Accelerated      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ DEVELOPMENT

### Hardware Requirements

**Minimum:**
- CPU: Multi-core processor (Intel i5 or equivalent)
- RAM: 8GB
- Storage: 10GB free space

**Recommended:**
- CPU: Intel i7/AMD Ryzen 7 or better
- RAM: 16GB
- GPU: NVIDIA GPU with 4GB+ VRAM (CUDA 11.8+)
- Storage: 20GB free space (for datasets)

### Dataset Information

**Datasets (not included in repository):**
- **ASVspoof2019 LA**: ~7.3 GB - Download from [official source](https://datashare.ed.ac.uk/handle/10283/3336)
- **LibriSpeech test-clean**: ~350 MB - Auto-download via `python utils.py download`

---

## ğŸ”’ SECURITY

The application uses self-signed SSL certificates for HTTPS:
- **Location**: `certificates/cert.pem`, `certificates/key.pem`
- **Note**: Browsers will show security warnings (expected)
- **Production**: Replace with proper SSL certificates from Let's Encrypt or CA

---

## ğŸ“ˆ PERFORMANCE BENCHMARKS

| Hardware | Inference Time | Throughput |
|----------|---------------|------------|
| **NVIDIA RTX 2050** | 14.8ms | 67 clips/sec |
| **NVIDIA RTX 3060** | 9.2ms | 108 clips/sec |
| **Intel i7 CPU** | 156ms | 6.4 clips/sec |

*Based on 4-second audio clips at 16kHz*

---

## ğŸ› TROUBLESHOOTING

**Issue: ModuleNotFoundError**
```bash
pip install -r backend/requirements.txt
```

**Issue: Port already in use**
```bash
# Windows
netstat -ano | findstr :5000
taskkill /PID <PID> /F
```

**Issue: SSL Certificate Warning**
- Expected for self-signed certificates
- Click "Advanced" â†’ "Proceed to localhost"

---

## ğŸ¤ CONTRIBUTING

Contributions welcome! Areas for improvement:
- Real-time microphone input
- Batch processing API
- Docker containerization
- Mobile app integration
- Additional TTS detection systems

---

## ğŸ“„ LICENSE

MIT License - See LICENSE file for details

---

## ğŸ™ ACKNOWLEDGMENTS

- **ASVspoof 2019 Challenge** - Comprehensive spoofing dataset
- **AASIST Authors** - State-of-the-art anti-spoofing architecture
- **LibriSpeech** - Diverse real speech samples
- **PyTorch Team** - Deep learning framework

---

## ğŸ“š REFERENCES

1. Jung, Jee-weon, et al. "AASIST: Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks." *ICASSP 2022*.
2. ASVspoof 2019: "The ASVspoof 2019 database." *Zenodo*, 2019.
3. LibriSpeech: Panayotov, V., et al. "Librispeech: An ASR corpus based on public domain audio books." *ICASSP 2015*.

---

<div align="center">

**ğŸ” Built for AI Security Research**

**Repository**: [github.com/anjo3902/Voice_Deepfake_Detection](https://github.com/anjo3902/Voice_Deepfake_Detection)

â­ Star this repo if you find it helpful!

</div>

